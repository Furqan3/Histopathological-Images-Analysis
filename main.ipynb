{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Download Dataset","metadata":{}},{"cell_type":"markdown","source":"The Dataset for this Project is Given on the drive with the name of ___Data___. ___Data___ folder has 2 subfolders with the name of ___Images___, Which contains Histopathological Images and ___Masks___ Which containg the masks of images.\nDownloading link for data set is https://drive.google.com/drive/folders/14DtM2x4UfIQR0au6LDARSb8YaLuagczJ?usp=sharing","metadata":{}},{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import os \nimport numpy as np \nimport seaborn as sns\nimport cv2 as cv \nimport glob\nimport matplotlib.pyplot as plt\nimport random\nfrom sklearn.metrics import confusion_matrix,accuracy_score,ConfusionMatrixDisplay\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.losses import *\nimport math\nimport tensorflow as tf\nfrom keras.utils.vis_utils import plot_model\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n","metadata":{"execution":{"iopub.status.busy":"2023-06-06T03:33:50.172585Z","iopub.execute_input":"2023-06-06T03:33:50.173162Z","iopub.status.idle":"2023-06-06T03:33:50.180242Z","shell.execute_reply.started":"2023-06-06T03:33:50.173128Z","shell.execute_reply":"2023-06-06T03:33:50.179304Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Segmentation","metadata":{}},{"cell_type":"markdown","source":"## Prepare Data","metadata":{}},{"cell_type":"code","source":"class Prepare_Data:\n    def __init__(self,image_path,mask_path):\n        # load all the images and masks from the given path\n        self.image_path = image_path\n        self.mask_path = mask_path\n        self.images = glob.glob(self.image_path)\n        self.masks = glob.glob(self.mask_path)\n        print(len(self.images),len(self.masks))\n        self.images.sort()\n        self.masks.sort()\n        self.image_list = []\n        self.mask_list = []\n    \n    def load_images(self):\n        # load all the images from the given path\n        for image in self.images:\n            img = cv.imread(image)\n            def gama(image,g):\n                image=np.divide(image,255)\n                gimage=255*(np.power(image,g))\n                return np.array(gimage,np.uint8)\n            img=gama(img,1.2)\n            img = cv.cvtColor(img,cv.COLOR_BGR2RGB)\n            self.image_list.append(img)\n        return np.array(self.image_list)\n    \n    def load_masks(self):\n        # load all the masks from the given path\n        for mask in self.masks:\n            img = cv.imread(mask)\n            img = cv.cvtColor(img,cv.COLOR_BGR2RGB)\n            self.mask_list.append(img)\n        return np.array(self.mask_list)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-06T03:33:50.182147Z","iopub.execute_input":"2023-06-06T03:33:50.182537Z","iopub.status.idle":"2023-06-06T03:33:50.193152Z","shell.execute_reply.started":"2023-06-06T03:33:50.182504Z","shell.execute_reply":"2023-06-06T03:33:50.192015Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def one_hot_encoding(masks,colormap):\n    new_mask = np.zeros((masks.shape[0], 256, 256, 12), dtype=bool)\n    for i in range(masks.shape[0]):\n        for j in colormap:\n            new_mask[i,:,:,j] = np.all(masks[i] == colormap[j], axis=2)\n    return new_mask","metadata":{"execution":{"iopub.status.busy":"2023-06-06T03:33:50.195205Z","iopub.execute_input":"2023-06-06T03:33:50.195676Z","iopub.status.idle":"2023-06-06T03:33:50.206237Z","shell.execute_reply.started":"2023-06-06T03:33:50.195647Z","shell.execute_reply":"2023-06-06T03:33:50.205415Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"colormap={\n    0: (108, 0, 155),\n    1: (145, 1, 122),\n    2: (216, 47, 148),\n    3: (254, 246, 242),\n    4: (181, 9, 130),\n    5: (236, 85, 157),\n    6: (73, 0, 106),\n    7: (248, 123, 168),\n    8: (0, 0, 0),\n    9: (127, 255, 255),\n    10: (127, 255, 142),\n    11: (255, 127, 127)    \n}\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-06T03:33:50.207677Z","iopub.execute_input":"2023-06-06T03:33:50.208053Z","iopub.status.idle":"2023-06-06T03:33:50.215614Z","shell.execute_reply.started":"2023-06-06T03:33:50.208007Z","shell.execute_reply":"2023-06-06T03:33:50.214685Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"data=Prepare_Data('/kaggle/input/dataset/data/Images/*.png','/kaggle/input/dataset/data/Masks/*.png')\nimages=data.load_images()\nmasks=data.load_masks()\ndel data\nmasks=one_hot_encoding(masks,colormap)\nimages,masks=shuffle(images,masks,random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-06-06T03:33:50.217680Z","iopub.execute_input":"2023-06-06T03:33:50.218378Z","iopub.status.idle":"2023-06-06T03:34:51.433465Z","shell.execute_reply.started":"2023-06-06T03:33:50.218346Z","shell.execute_reply":"2023-06-06T03:34:51.432383Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"1200 1200\n","output_type":"stream"}]},{"cell_type":"code","source":"for i in range(12):\n    plt.subplot(3,4,i+1)\n    plt.imshow(masks[1,:,:,i])\n    plt.title(i)\n    plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2023-06-06T03:34:51.434858Z","iopub.execute_input":"2023-06-06T03:34:51.435652Z","iopub.status.idle":"2023-06-06T03:34:52.319040Z","shell.execute_reply.started":"2023-06-06T03:34:51.435616Z","shell.execute_reply":"2023-06-06T03:34:52.318005Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 12 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"## Create Model","metadata":{}},{"cell_type":"code","source":"def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):\n    \"\"\"Function to add 2 convolutional layers with the parameters passed to it\"\"\"\n    # First layer\n    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size),\\\n                kernel_initializer='he_normal', padding='same')(input_tensor)\n    if batchnorm:\n        x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    \n    # Second layer\n    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size),\\\n                kernel_initializer='he_normal', padding='same')(x)\n    if batchnorm:\n        x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    \n    return x\n\ndef Unet(input_img, n_filters=16, dropout=0.1, batchnorm=True, num_classes=12):\n    \"\"\"Function to define the UNET Model\"\"\"\n    # Contracting Path\n    c1 = conv2d_block(input_img, n_filters * 1, kernel_size=3, batchnorm=batchnorm)\n    p1 = MaxPooling2D((2, 2))(c1)\n    p1 = Dropout(dropout)(p1)\n    \n    c2 = conv2d_block(p1, n_filters * 2, kernel_size=3, batchnorm=batchnorm)\n    p2 = MaxPooling2D((2, 2))(c2)\n    p2 = Dropout(dropout)(p2)\n    \n    c3 = conv2d_block(p2, n_filters * 4, kernel_size=3, batchnorm=batchnorm)\n    p3 = MaxPooling2D((2, 2))(c3)\n    p3 = Dropout(dropout)(p3)\n    \n    c4 = conv2d_block(p3, n_filters * 8, kernel_size=3, batchnorm=batchnorm)\n    p4 = MaxPooling2D((2, 2))(c4)\n    p4 = Dropout(dropout)(p4)\n    \n    c5 = conv2d_block(p4, n_filters=n_filters * 16, kernel_size=3, batchnorm=batchnorm)\n    \n    # Expansive Path\n    u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides=(2, 2), padding='same')(c5)\n    u6 = concatenate([u6, c4])\n    u6 = Dropout(dropout)(u6)\n    c6 = conv2d_block(u6, n_filters * 8, kernel_size=3, batchnorm=batchnorm)\n    \n    u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides=(2, 2), padding='same')(c6)\n    u7 = concatenate([u7, c3])\n    u7 = Dropout(dropout)(u7)\n    c7 = conv2d_block(u7, n_filters * 4, kernel_size=3, batchnorm=batchnorm)\n    \n    u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides=(2, 2), padding='same')(c7)\n    u8 = concatenate([u8, c2])\n    u8 = Dropout(dropout)(u8)\n    c8 = conv2d_block(u8, n_filters * 2, kernel_size=3, batchnorm=batchnorm)\n    \n    u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides=(2, 2), padding='same')(c8)\n    u9 = concatenate([u9, c1])\n    u9 = Dropout(dropout)(u9)\n    c9 = conv2d_block(u9, n_filters * 1, kernel_size=3, batchnorm=batchnorm)\n    \n    outputs = Conv2D(num_classes, (1, 1), activation='softmax')(c9)\n    model = Model(inputs=[input_img], outputs=[outputs])\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2023-06-06T03:34:52.321834Z","iopub.execute_input":"2023-06-06T03:34:52.322186Z","iopub.status.idle":"2023-06-06T03:34:52.339400Z","shell.execute_reply.started":"2023-06-06T03:34:52.322153Z","shell.execute_reply":"2023-06-06T03:34:52.338493Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"\nimport keras.backend as K\n\ndef iou_coefficient(y_true, y_pred):\n    intersection = K.sum(K.abs(y_true * y_pred))\n    union = K.sum(y_true) + K.sum(y_pred) - intersection\n    iou = intersection / (union + K.epsilon())\n    return iou\n\ndef mean_iou(y_true, y_pred):\n    iou = iou_coefficient(y_true, y_pred)\n    mean_iou = K.mean(iou)\n    return mean_iou\n\ninput_img = Input((256, 256, 3), name='img')\nmodel = Unet(input_img, n_filters=16, dropout=0.05, batchnorm=True, num_classes=12)\nmodel.compile(optimizer=Adam(), loss=\"categorical_crossentropy\", metrics=[\"accuracy\", mean_iou])\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2023-06-06T03:34:52.340775Z","iopub.execute_input":"2023-06-06T03:34:52.341361Z","iopub.status.idle":"2023-06-06T03:34:55.809716Z","shell.execute_reply.started":"2023-06-06T03:34:52.341323Z","shell.execute_reply":"2023-06-06T03:34:55.808970Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n img (InputLayer)               [(None, 256, 256, 3  0           []                               \n                                )]                                                                \n                                                                                                  \n conv2d (Conv2D)                (None, 256, 256, 16  448         ['img[0][0]']                    \n                                )                                                                 \n                                                                                                  \n batch_normalization (BatchNorm  (None, 256, 256, 16  64         ['conv2d[0][0]']                 \n alization)                     )                                                                 \n                                                                                                  \n activation (Activation)        (None, 256, 256, 16  0           ['batch_normalization[0][0]']    \n                                )                                                                 \n                                                                                                  \n conv2d_1 (Conv2D)              (None, 256, 256, 16  2320        ['activation[0][0]']             \n                                )                                                                 \n                                                                                                  \n batch_normalization_1 (BatchNo  (None, 256, 256, 16  64         ['conv2d_1[0][0]']               \n rmalization)                   )                                                                 \n                                                                                                  \n activation_1 (Activation)      (None, 256, 256, 16  0           ['batch_normalization_1[0][0]']  \n                                )                                                                 \n                                                                                                  \n max_pooling2d (MaxPooling2D)   (None, 128, 128, 16  0           ['activation_1[0][0]']           \n                                )                                                                 \n                                                                                                  \n dropout (Dropout)              (None, 128, 128, 16  0           ['max_pooling2d[0][0]']          \n                                )                                                                 \n                                                                                                  \n conv2d_2 (Conv2D)              (None, 128, 128, 32  4640        ['dropout[0][0]']                \n                                )                                                                 \n                                                                                                  \n batch_normalization_2 (BatchNo  (None, 128, 128, 32  128        ['conv2d_2[0][0]']               \n rmalization)                   )                                                                 \n                                                                                                  \n activation_2 (Activation)      (None, 128, 128, 32  0           ['batch_normalization_2[0][0]']  \n                                )                                                                 \n                                                                                                  \n conv2d_3 (Conv2D)              (None, 128, 128, 32  9248        ['activation_2[0][0]']           \n                                )                                                                 \n                                                                                                  \n batch_normalization_3 (BatchNo  (None, 128, 128, 32  128        ['conv2d_3[0][0]']               \n rmalization)                   )                                                                 \n                                                                                                  \n activation_3 (Activation)      (None, 128, 128, 32  0           ['batch_normalization_3[0][0]']  \n                                )                                                                 \n                                                                                                  \n max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 32)  0           ['activation_3[0][0]']           \n                                                                                                  \n dropout_1 (Dropout)            (None, 64, 64, 32)   0           ['max_pooling2d_1[0][0]']        \n                                                                                                  \n conv2d_4 (Conv2D)              (None, 64, 64, 64)   18496       ['dropout_1[0][0]']              \n                                                                                                  \n batch_normalization_4 (BatchNo  (None, 64, 64, 64)  256         ['conv2d_4[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n activation_4 (Activation)      (None, 64, 64, 64)   0           ['batch_normalization_4[0][0]']  \n                                                                                                  \n conv2d_5 (Conv2D)              (None, 64, 64, 64)   36928       ['activation_4[0][0]']           \n                                                                                                  \n batch_normalization_5 (BatchNo  (None, 64, 64, 64)  256         ['conv2d_5[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n activation_5 (Activation)      (None, 64, 64, 64)   0           ['batch_normalization_5[0][0]']  \n                                                                                                  \n max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 64)  0           ['activation_5[0][0]']           \n                                                                                                  \n dropout_2 (Dropout)            (None, 32, 32, 64)   0           ['max_pooling2d_2[0][0]']        \n                                                                                                  \n conv2d_6 (Conv2D)              (None, 32, 32, 128)  73856       ['dropout_2[0][0]']              \n                                                                                                  \n batch_normalization_6 (BatchNo  (None, 32, 32, 128)  512        ['conv2d_6[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n activation_6 (Activation)      (None, 32, 32, 128)  0           ['batch_normalization_6[0][0]']  \n                                                                                                  \n conv2d_7 (Conv2D)              (None, 32, 32, 128)  147584      ['activation_6[0][0]']           \n                                                                                                  \n batch_normalization_7 (BatchNo  (None, 32, 32, 128)  512        ['conv2d_7[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n activation_7 (Activation)      (None, 32, 32, 128)  0           ['batch_normalization_7[0][0]']  \n                                                                                                  \n max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 128)  0          ['activation_7[0][0]']           \n                                                                                                  \n dropout_3 (Dropout)            (None, 16, 16, 128)  0           ['max_pooling2d_3[0][0]']        \n                                                                                                  \n conv2d_8 (Conv2D)              (None, 16, 16, 256)  295168      ['dropout_3[0][0]']              \n                                                                                                  \n batch_normalization_8 (BatchNo  (None, 16, 16, 256)  1024       ['conv2d_8[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n activation_8 (Activation)      (None, 16, 16, 256)  0           ['batch_normalization_8[0][0]']  \n                                                                                                  \n conv2d_9 (Conv2D)              (None, 16, 16, 256)  590080      ['activation_8[0][0]']           \n                                                                                                  \n batch_normalization_9 (BatchNo  (None, 16, 16, 256)  1024       ['conv2d_9[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n activation_9 (Activation)      (None, 16, 16, 256)  0           ['batch_normalization_9[0][0]']  \n                                                                                                  \n conv2d_transpose (Conv2DTransp  (None, 32, 32, 128)  295040     ['activation_9[0][0]']           \n ose)                                                                                             \n                                                                                                  \n concatenate (Concatenate)      (None, 32, 32, 256)  0           ['conv2d_transpose[0][0]',       \n                                                                  'activation_7[0][0]']           \n                                                                                                  \n dropout_4 (Dropout)            (None, 32, 32, 256)  0           ['concatenate[0][0]']            \n                                                                                                  \n conv2d_10 (Conv2D)             (None, 32, 32, 128)  295040      ['dropout_4[0][0]']              \n                                                                                                  \n batch_normalization_10 (BatchN  (None, 32, 32, 128)  512        ['conv2d_10[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_10 (Activation)     (None, 32, 32, 128)  0           ['batch_normalization_10[0][0]'] \n                                                                                                  \n conv2d_11 (Conv2D)             (None, 32, 32, 128)  147584      ['activation_10[0][0]']          \n                                                                                                  \n batch_normalization_11 (BatchN  (None, 32, 32, 128)  512        ['conv2d_11[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_11 (Activation)     (None, 32, 32, 128)  0           ['batch_normalization_11[0][0]'] \n                                                                                                  \n conv2d_transpose_1 (Conv2DTran  (None, 64, 64, 64)  73792       ['activation_11[0][0]']          \n spose)                                                                                           \n                                                                                                  \n concatenate_1 (Concatenate)    (None, 64, 64, 128)  0           ['conv2d_transpose_1[0][0]',     \n                                                                  'activation_5[0][0]']           \n                                                                                                  \n dropout_5 (Dropout)            (None, 64, 64, 128)  0           ['concatenate_1[0][0]']          \n                                                                                                  \n conv2d_12 (Conv2D)             (None, 64, 64, 64)   73792       ['dropout_5[0][0]']              \n                                                                                                  \n batch_normalization_12 (BatchN  (None, 64, 64, 64)  256         ['conv2d_12[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_12 (Activation)     (None, 64, 64, 64)   0           ['batch_normalization_12[0][0]'] \n                                                                                                  \n conv2d_13 (Conv2D)             (None, 64, 64, 64)   36928       ['activation_12[0][0]']          \n                                                                                                  \n batch_normalization_13 (BatchN  (None, 64, 64, 64)  256         ['conv2d_13[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_13 (Activation)     (None, 64, 64, 64)   0           ['batch_normalization_13[0][0]'] \n                                                                                                  \n conv2d_transpose_2 (Conv2DTran  (None, 128, 128, 32  18464      ['activation_13[0][0]']          \n spose)                         )                                                                 \n                                                                                                  \n concatenate_2 (Concatenate)    (None, 128, 128, 64  0           ['conv2d_transpose_2[0][0]',     \n                                )                                 'activation_3[0][0]']           \n                                                                                                  \n dropout_6 (Dropout)            (None, 128, 128, 64  0           ['concatenate_2[0][0]']          \n                                )                                                                 \n                                                                                                  \n conv2d_14 (Conv2D)             (None, 128, 128, 32  18464       ['dropout_6[0][0]']              \n                                )                                                                 \n                                                                                                  \n batch_normalization_14 (BatchN  (None, 128, 128, 32  128        ['conv2d_14[0][0]']              \n ormalization)                  )                                                                 \n                                                                                                  \n activation_14 (Activation)     (None, 128, 128, 32  0           ['batch_normalization_14[0][0]'] \n                                )                                                                 \n                                                                                                  \n conv2d_15 (Conv2D)             (None, 128, 128, 32  9248        ['activation_14[0][0]']          \n                                )                                                                 \n                                                                                                  \n batch_normalization_15 (BatchN  (None, 128, 128, 32  128        ['conv2d_15[0][0]']              \n ormalization)                  )                                                                 \n                                                                                                  \n activation_15 (Activation)     (None, 128, 128, 32  0           ['batch_normalization_15[0][0]'] \n                                )                                                                 \n                                                                                                  \n conv2d_transpose_3 (Conv2DTran  (None, 256, 256, 16  4624       ['activation_15[0][0]']          \n spose)                         )                                                                 \n                                                                                                  \n concatenate_3 (Concatenate)    (None, 256, 256, 32  0           ['conv2d_transpose_3[0][0]',     \n                                )                                 'activation_1[0][0]']           \n                                                                                                  \n dropout_7 (Dropout)            (None, 256, 256, 32  0           ['concatenate_3[0][0]']          \n                                )                                                                 \n                                                                                                  \n conv2d_16 (Conv2D)             (None, 256, 256, 16  4624        ['dropout_7[0][0]']              \n                                )                                                                 \n                                                                                                  \n batch_normalization_16 (BatchN  (None, 256, 256, 16  64         ['conv2d_16[0][0]']              \n ormalization)                  )                                                                 \n                                                                                                  \n activation_16 (Activation)     (None, 256, 256, 16  0           ['batch_normalization_16[0][0]'] \n                                )                                                                 \n                                                                                                  \n conv2d_17 (Conv2D)             (None, 256, 256, 16  2320        ['activation_16[0][0]']          \n                                )                                                                 \n                                                                                                  \n batch_normalization_17 (BatchN  (None, 256, 256, 16  64         ['conv2d_17[0][0]']              \n ormalization)                  )                                                                 \n                                                                                                  \n activation_17 (Activation)     (None, 256, 256, 16  0           ['batch_normalization_17[0][0]'] \n                                )                                                                 \n                                                                                                  \n conv2d_18 (Conv2D)             (None, 256, 256, 12  204         ['activation_17[0][0]']          \n                                )                                                                 \n                                                                                                  \n==================================================================================================\nTotal params: 2,164,780\nTrainable params: 2,161,836\nNon-trainable params: 2,944\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Train Model","metadata":{}},{"cell_type":"code","source":"\ncheckpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\nhistory = model.fit(images, masks, batch_size=4, epochs=50, validation_split=0.2, callbacks=[checkpoint])","metadata":{"execution":{"iopub.status.busy":"2023-06-06T03:35:13.122139Z","iopub.execute_input":"2023-06-06T03:35:13.122516Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"2023-06-06 03:35:20.584749: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"240/240 [==============================] - 35s 55ms/step - loss: 1.3020 - accuracy: 0.6459 - mean_iou: 0.2662 - val_loss: 4.2468 - val_accuracy: 0.2494 - val_mean_iou: 0.1077\nEpoch 2/50\n240/240 [==============================] - 12s 48ms/step - loss: 0.9521 - accuracy: 0.7189 - mean_iou: 0.3935 - val_loss: 1.6997 - val_accuracy: 0.3552 - val_mean_iou: 0.1724\nEpoch 3/50\n240/240 [==============================] - 12s 50ms/step - loss: 0.8157 - accuracy: 0.7421 - mean_iou: 0.4475 - val_loss: 2.5654 - val_accuracy: 0.1462 - val_mean_iou: 0.1043\nEpoch 4/50\n240/240 [==============================] - 11s 48ms/step - loss: 0.7532 - accuracy: 0.7614 - mean_iou: 0.4822 - val_loss: 2.3704 - val_accuracy: 0.3532 - val_mean_iou: 0.1791\nEpoch 5/50\n240/240 [==============================] - 11s 47ms/step - loss: 0.7087 - accuracy: 0.7706 - mean_iou: 0.5010 - val_loss: 2.1177 - val_accuracy: 0.3574 - val_mean_iou: 0.1854\nEpoch 6/50\n240/240 [==============================] - 12s 49ms/step - loss: 0.6514 - accuracy: 0.7841 - mean_iou: 0.5280 - val_loss: 1.1203 - val_accuracy: 0.5794 - val_mean_iou: 0.3137\nEpoch 7/50\n240/240 [==============================] - 11s 48ms/step - loss: 0.6326 - accuracy: 0.7914 - mean_iou: 0.5423 - val_loss: 1.3225 - val_accuracy: 0.6697 - val_mean_iou: 0.4525\nEpoch 8/50\n240/240 [==============================] - 12s 49ms/step - loss: 0.5980 - accuracy: 0.7985 - mean_iou: 0.5572 - val_loss: 1.1007 - val_accuracy: 0.6055 - val_mean_iou: 0.3807\nEpoch 9/50\n240/240 [==============================] - 12s 50ms/step - loss: 0.5909 - accuracy: 0.7997 - mean_iou: 0.5641 - val_loss: 4.4992 - val_accuracy: 0.3652 - val_mean_iou: 0.1951\nEpoch 10/50\n240/240 [==============================] - 12s 50ms/step - loss: 0.5864 - accuracy: 0.8029 - mean_iou: 0.5672 - val_loss: 1.2785 - val_accuracy: 0.6558 - val_mean_iou: 0.2284\nEpoch 11/50\n240/240 [==============================] - 11s 47ms/step - loss: 0.5536 - accuracy: 0.8125 - mean_iou: 0.5806 - val_loss: 1.6358 - val_accuracy: 0.5907 - val_mean_iou: 0.3957\nEpoch 12/50\n240/240 [==============================] - 12s 50ms/step - loss: 0.5500 - accuracy: 0.8140 - mean_iou: 0.5871 - val_loss: 2.6642 - val_accuracy: 0.3489 - val_mean_iou: 0.1529\nEpoch 13/50\n240/240 [==============================] - 12s 50ms/step - loss: 0.5465 - accuracy: 0.8145 - mean_iou: 0.5900 - val_loss: 2.0387 - val_accuracy: 0.3883 - val_mean_iou: 0.2097\nEpoch 14/50\n240/240 [==============================] - 12s 50ms/step - loss: 0.5312 - accuracy: 0.8212 - mean_iou: 0.6014 - val_loss: 1.6764 - val_accuracy: 0.3298 - val_mean_iou: 0.1647\nEpoch 15/50\n240/240 [==============================] - 11s 48ms/step - loss: 0.5177 - accuracy: 0.8230 - mean_iou: 0.6056 - val_loss: 2.4783 - val_accuracy: 0.3726 - val_mean_iou: 0.1916\nEpoch 16/50\n 21/240 [=>............................] - ETA: 9s - loss: 0.4947 - accuracy: 0.8295 - mean_iou: 0.6121","output_type":"stream"}]},{"cell_type":"markdown","source":"## Plot Learning curve","metadata":{}},{"cell_type":"code","source":"\nplt.figure(figsize=(12, 6))\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Learning Curve')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\n# Find the epoch with the best validation loss\nbest_epoch = np.argmin(history.history['val_loss'])\n\n# Add a cross marker at the best epoch\nbest_loss = history.history['val_loss'][best_epoch]\nplt.scatter(best_epoch, best_loss, marker='x', color='r', label='Best Model')\n\nplt.legend()\nplt.show()\n\nplt.figure(figsize=(12, 6))\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\n# Add a cross marker at the best epoch\nbest_accuracy = history.history['val_accuracy'][best_epoch]\nplt.scatter(best_epoch, best_accuracy, marker='x', color='r', label='Best Model')\n\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-06T03:34:55.839494Z","iopub.status.idle":"2023-06-06T03:34:55.839987Z","shell.execute_reply.started":"2023-06-06T03:34:55.839732Z","shell.execute_reply":"2023-06-06T03:34:55.839757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=Prepare_Data('/kaggle/input/dataset/data/Train_img/*.png','/kaggle/input/dataset/data/Train_mask/*.png')\nTest_images=data.load_images()\nTest_masks=data.load_masks()\ndel data\nmasks=one_hot_encoding(Test_masks,colormap)\nTest_images,Test_masks=shuffle(Test_images,masks,random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-06-06T03:34:55.841421Z","iopub.status.idle":"2023-06-06T03:34:55.841863Z","shell.execute_reply.started":"2023-06-06T03:34:55.841628Z","shell.execute_reply":"2023-06-06T03:34:55.841650Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# F1 Score and  Plot Confusion Matrix\nfrom sklearn.metrics import f1_score, confusion_matrix\nmodel.load_weights('best_model.h5')\npreds = model.predict(Test_images, verbose=1)\npreds_t = (preds > 0.5).astype(np.uint8)\n\nf1 = f1_score(Test_masks.reshape(-1, 12).argmax(axis=1), preds_t.reshape(-1, 12).argmax(axis=1), average='micro')\nprint('F1 score: {:.3f}'.format(f1))\n\ncm = confusion_matrix(Test_masks.reshape(-1, 12).argmax(axis=1), preds_t.reshape(-1, 12).argmax(axis=1))\ncm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\nplt.figure(figsize=(12, 12))\nsns.heatmap(cm, annot=True, square=True, cmap='Blues', xticklabels=colormap, yticklabels=colormap)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nplt.title('Confusion matrix: F1-score={:.3f}'.format(f1), size=15)\nplt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-06T03:34:55.842998Z","iopub.status.idle":"2023-06-06T03:34:55.843412Z","shell.execute_reply.started":"2023-06-06T03:34:55.843190Z","shell.execute_reply":"2023-06-06T03:34:55.843211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Classification","metadata":{}},{"cell_type":"markdown","source":"## Prepare Data","metadata":{}},{"cell_type":"code","source":"data=Prepare_Data('/kaggle/input/dataset/data/Masks/*.png','/kaggle/input/dataset/data/Train_mask/*.png')\nTrain_masks=data.load_images()\nTest_masks=data.load_masks()\nTrain_masks_data=one_hot_encoding(Train_masks,colormap)\nTest_masks_data=one_hot_encoding(Test_masks,colormap)\nTrain_masks=os.listdir('/kaggle/input/dataset/data/Masks/')\nTrain_masks.sort\nTest_masks=os.listdir('/kaggle/input/dataset/data/Train_mask/')\nTest_masks.sort\nTrain_labels=np.zeros((len(Train_masks),3))\nTest_labels=np.zeros((len(Test_masks),3))\n\nfor i in range(len(Train_masks)):\n    if Train_masks[i][0]=='B':\n        Train_labels[i][0]=1\n    elif Train_masks[i][0]=='S':\n        Train_labels[i][1]=1\n    else:\n        Train_labels[i][2]=1\n        \nfor i in range(len(Test_masks)):\n    if Test_masks[i][0]=='B':\n        Test_labels[i][0]=1\n    elif Test_masks[i][0]=='S':\n        Test_labels[i][1]=1\n    else:\n        Test_labels[i][2]=1\n    \n","metadata":{"execution":{"iopub.status.busy":"2023-06-06T03:34:55.844530Z","iopub.status.idle":"2023-06-06T03:34:55.844965Z","shell.execute_reply.started":"2023-06-06T03:34:55.844734Z","shell.execute_reply":"2023-06-06T03:34:55.844757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Model","metadata":{}},{"cell_type":"code","source":"class Classification:\n    def __init__(self):\n        pass\n    def build(self,classes):\n        inputs=Input(shape=(256,256,12))\n        conv1=Conv2D(8,3,activation='relu',padding='same')(inputs)\n        conv1=BatchNormalization()(conv1)\n        Pooll=MaxPooling2D(pool_size=(2,2))(conv1)\n        \n        conv2=Conv2D(16,3,activation='relu',padding='same')(Pooll)\n        conv2=BatchNormalization()(conv2)\n        Pooll=MaxPooling2D(pool_size=(2,2))(conv2)\n    \n        conv3=Conv2D(32,3,activation='relu',padding='same')(Pooll)\n        conv3=BatchNormalization()(conv3)\n        Pooll=MaxPooling2D(pool_size=(2,2))(conv3)\n        \n        conv4=Conv2D(64,3,activation='relu',padding='same')(Pooll)\n        conv4=BatchNormalization()(conv4)\n        Pooll=MaxPooling2D(pool_size=(2,2))(conv4)\n        \n        conv5=Conv2D(128,3,activation='relu',padding='same')(Pooll)\n        conv5=BatchNormalization()(conv5)\n        drop5=Dropout(0.5)(conv5)\n        \n        x=GlobalAveragePooling2D()(drop5)\n        \n        x=Dense(128,activation='relu',name='Dense')(x)\n        x=Dense(64,activation='relu',name='Dense1')(x)\n        x=Dense(32,activation='relu',name='Dense2')(x)\n        x=Dense(16,activation='relu',name='Dense3')(x)\n        x=Dense(8,activation='relu',name='Dense4')(x)\n        x=Dense(classes,activation='softmax',name='Dense5')(x)\n        \n        mymodel=Model(inputs=inputs,outputs=x)\n        optimizer=Adam(lr=0.00001)\n        mymodel.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n        mymodel.summary()\n        return mymodel\n    \n","metadata":{"execution":{"iopub.status.busy":"2023-06-06T03:34:55.850414Z","iopub.status.idle":"2023-06-06T03:34:55.850964Z","shell.execute_reply.started":"2023-06-06T03:34:55.850733Z","shell.execute_reply":"2023-06-06T03:34:55.850756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Classification_model = Classification()\nClassification_model=Classification_model.build(3)","metadata":{"execution":{"iopub.status.busy":"2023-06-06T03:34:55.852069Z","iopub.status.idle":"2023-06-06T03:34:55.852551Z","shell.execute_reply.started":"2023-06-06T03:34:55.852276Z","shell.execute_reply":"2023-06-06T03:34:55.852300Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train Model","metadata":{}},{"cell_type":"code","source":"history=Classification_model.fit(Train_masks_data,Train_labels,epochs=100,batch_size=32,validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2023-06-06T03:34:55.861032Z","iopub.status.idle":"2023-06-06T03:34:55.861506Z","shell.execute_reply.started":"2023-06-06T03:34:55.861263Z","shell.execute_reply":"2023-06-06T03:34:55.861285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loss = history.history['loss']\nval_loss = history.history['val_loss']\n\n# Get the training and validation accuracy values from the history object\ntrain_acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\n# Plot the training and validation loss\nplt.figure(figsize=(8, 6))\nplt.plot(train_loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.title('Learning Curve - Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\n# Plot the training and validation accuracy\nplt.figure(figsize=(8, 6))\nplt.plot(train_acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.title('Learning Curve - Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-06T03:34:55.862294Z","iopub.status.idle":"2023-06-06T03:34:55.862731Z","shell.execute_reply.started":"2023-06-06T03:34:55.862498Z","shell.execute_reply":"2023-06-06T03:34:55.862519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# F1 Score and Confusion Matrix\nfrom sklearn.metrics import f1_score, confusion_matrix\nimport seaborn as sns\n\nTest_pred = Classification_model.predict(Test_masks_data)\nTest_pred_classes = np.argmax(Test_pred, axis=1)\nTest_true = np.argmax(Test_labels, axis=1)\nconfusion_mtx = confusion_matrix(Test_true, Test_pred_classes) \nplt.figure(figsize=(10, 8))\nsns.heatmap(confusion_mtx, annot=True, fmt=\"d\")\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()\n\n\n\n\n# print f1 scores\nprint(\"F1 Score for each class\")\nprint(\"BCC: \", f1_score(Test_true, Test_pred_classes, average=None)[0])\nprint(\"SCC \", f1_score(Test_true, Test_pred_classes, average=None)[1])\nprint(\"IEC: \", f1_score(Test_true, Test_pred_classes, average=None)[2])\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-06T03:34:55.863566Z","iopub.status.idle":"2023-06-06T03:34:55.863987Z","shell.execute_reply.started":"2023-06-06T03:34:55.863767Z","shell.execute_reply":"2023-06-06T03:34:55.863787Z"},"trusted":true},"execution_count":null,"outputs":[]}]}